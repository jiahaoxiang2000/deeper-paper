\documentclass[final, twoside]{IEEEtran} % regular paper
%\documentclass[journal]{IEEEtran}
%\documentclass[journal, draftcls, onecolumn, 11pt]{IEEEtran} % for review
\setlength\columnwidth{0.5\textwidth} % this must be set in one-column mode
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amssymb, amsmath, amsthm, bm}
\usepackage{enumitem}
\newcommand{\Mod}[1]{\ (\mathrm{mod}\ #1)}
\makeatletter
\newcommand{\tpmod}[1]{{\@displayfalse\pmod{#1}}}
\makeatother
\newcommand{\var}[1]{\mathit{#1}}
\newcommand{\iu}{{i\mkern1mu}}
% \renewcommand{\arraystretch}{0.6} because \baselinestretch is 1.6667
\usepackage{graphicx, color}
\graphicspath{{figures-pdf/}}
\usepackage{cite}
\usepackage{url}
\usepackage{diagbox}
\usepackage[aboveskip=1pt]{subcaption}
\usepackage{pbox}
%\usepackage[retainorgcmds]{IEEEtrantools}
%\usepackage[mathlines]{lineno}
%\linenumbers
%\setlength\linenumbersep{0.03in}
\usepackage{enumitem}
%\usepackage{algorithm}
%\usepackage[ruled,linesnumbered]{algorithm2e} 
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}

\usepackage{algpseudocode}
\usepackage{multirow, bigstrut}
\usepackage{tabularx}
\usepackage{arydshln}
\usepackage{empheq}
\usepackage{threeparttable}

%%%% TIKZ PACKAGES FOR FIGURES %%%%
\usepackage{tikz}
\usetikzlibrary{positioning}       % relative positioning
\usetikzlibrary{shapes.geometric}  % shapes like diamond, ellipse
\usetikzlibrary{arrows.meta}       % modern arrow tips
\usetikzlibrary{fit}               % fitting nodes around others
\usetikzlibrary{backgrounds}       % background layers
\usetikzlibrary{calc}              % coordinate calculations
\usetikzlibrary{decorations.pathreplacing}  % braces for annotations

%%%% COLOR PACKAGE FOR HIGHLIGHTING %%%%
\usepackage{xcolor}
\usepackage[normalem]{ulem}  % For wavy underline
\newcommand{\bluet}[1]{\textcolor{blue}{#1}}

%\usepackage{dblfloatfix}
%\usepackage{datetime}
\newlength\OneImW
\setlength\OneImW{0.38\columnwidth}

\newlength\BigOneImW
\setlength\BigOneImW{0.85\columnwidth}

\newlength\twofigwidth
\setlength\twofigwidth{0.46\columnwidth}

\newlength\ThreeImW
\setlength\ThreeImW{0.31\columnwidth}

\newlength\sfigwidth
\setlength\sfigwidth{0.3\columnwidth}

\newlength\vfigskip
\setlength\vfigskip{4em}

\newcommand\mymatrix[1]{\bm{\mathrm{#1}}}
\newcommand{\sign}[1]{\mathrm{sgn}{#1}} 

\hyphenation{op-tical net-works semi-conduc-tor}

\newlength\figsep
\setlength\figsep{1.5em}

\usepackage{stfloats} 

\newtheorem{Proposition}{Proposition}
\newtheorem{Definition}{Definition}
\newtheorem{Corollary}{Corollary}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
%\def\stackrel#1#2{\mathrel{\mathop{#2}\limits^{#1}}}

\DeclareMathOperator*{\lcm}{lcm}
%%% Vector and matrix operators
\newcommand{\x}[0]{{\bf x}}
\newcommand{\vct}[1]{\bm{#1}}
\newcommand{\mtx}[1]{\bm{#1}}

%%% Constants, vectors, and matrices with names
\newcommand{\atom}{\vct{\phi}}
\newcommand{\Fee}{\mtx{\Phi}}

\usepackage[bookmarks=false]{hyperref}
\hypersetup{
 linktocpage=true, pdfborderstyle={/S/S/W 1}, hyperindex=true, bookmarks=true, bookmarksopen=true, bookmarksnumbered=true
}
%\renewcommand\baselinestretch{1}
%------------------------------------------------------------
%\usepackage{setspace}
%\setstretch{1.1}
% The setspace package changes only the spacing of the body text and the bibliography.

\begin{document}

\title{ML-DSA Digital Signatures in Resource-Constrained MQTT Environments}

\author{ Jiahao Xiang, Lang Li  and Jingya Feng

	\thanks{This research is supported by the Open Fund of Hunan Engineering Research Center for Cyberspace Security Technology and Application at Hengyang Normal University (2025HSKFJJ031), "the 14th Five-Year Plan" Key Disciplines and Application-oriented Special Disciplines of Hunan Province (Xiangjiaotong [2022] 351), the Science and Technology Innovation Program of Hunan Province (2016TP1020). \textit{(Corresponding
			author: Lang Li.)}}

	\thanks{The authors are with the Hunan Provincial Key Laboratory of Intelligent Information Processing and Application, the Hunan Engineering Research Center of Cyberspace Security Technology and Applications, and the College of Computer Science and Technology, Hengyang Normal University, Hengyang 421002, China (e-mail: jiahaoxiang2000@gmail.com; lilang911@126.com; fengjyk@126.com).}

}

% The paper headers
\markboth{IEEE Transactions}{Xiang \MakeLowercase{et al.}}

\maketitle

\begin{abstract}
	Large-scale quantum computers necessitate migration of Internet of Things (IoT) systems to post-quantum cryptographic standards. While NIST has standardized ML-DSA (Module-Lattice-Based Digital Signature Algorithm) for digital signatures, practical deployment of post-quantum authentication in resource-constrained IoT environments remains inadequately characterized. This work evaluates ML-DSA integration within MQTT-based IoT systems through comprehensive performance analysis on ARM Cortex-M4 microcontrollers and proposes an adaptive security level selection protocol that dynamically selects ML-DSA parameter sets based on message criticality and device resource state. The methodology encompasses signature generation and verification benchmarking, memory utilization analysis, and protocol overhead assessment under realistic IoT constraints. Performance measurements quantify 70--122$\times$ computational overhead relative to ECDSA, with signature generation latencies of 657--1,150\,ms across parameter sets. The proposed adaptive protocol reduces average signing overhead by 15.8--41.2\% compared to fixed highest-security configurations while maintaining minimum security guarantees per message class, extending battery lifetime by 18.8--55.2\% for energy-constrained deployments. These findings reveal fundamental trade-offs between post-quantum security and IoT performance requirements, providing both characterization data and an adaptive optimization mechanism for practical deployment in resource-limited environments.
\end{abstract}

\begin{IEEEkeywords}
	Post-Quantum Cryptography, ML-DSA, MQTT Protocol, IoT Security, Resource-Constrained Devices
\end{IEEEkeywords}

\section{Introduction}

\IEEEPARstart{T}{he} emergence of quantum computing fundamentally undermines current cryptographic infrastructures, necessitating systematic migration to post-quantum cryptographic standards across all computing domains~\cite{Khalid2019}. The National Institute of Standards and Technology (NIST) has formalized ML-DSA (Module-Lattice-Based Digital Signature Algorithm) within FIPS 204~\cite{NIST-FIPS-204}, establishing this CRYSTALS-Dilithium-based scheme as the primary standard for post-quantum digital signatures.

\IEEEpubidadjcol % must call \IEEEpubidadjcol in the second column for its text to clear the %IEEEpubid mark. 

The transition from theoretical post-quantum standardization to practical deployment has revealed fundamental implementation challenges extending beyond algorithmic considerations~\cite{MLDSAHardware2024}. Post-quantum signature schemes impose substantial computational and storage overhead compared to classical alternatives. ML-DSA signatures span 2,420-4,627 bytes across security levels, representing 30-70$\times$ size increases relative to 64-byte ECDSA signatures. These expanded signature sizes, combined with elevated computational demands, substantially exceed the computational and memory capabilities of resource-constrained devices~\cite{HwangKim2024}.

Internet of Things (IoT) systems exemplify these deployment challenges, where computational, memory, and energy limitations constrain cryptographic implementation choices~\cite{Ghosh2019}. Despite performance overhead, signature-based authentication remains essential for applications requiring cryptographic non-repudiation, audit trails, and public key infrastructure compatibility. The MQTT protocol, widely adopted for IoT messaging due to its lightweight design, experiences performance degradation when post-quantum signatures introduce overhead on resource-constrained devices. This disparity between standardization progress and deployment feasibility motivates systematic performance characterization.

This work addresses ML-DSA integration within MQTT-based IoT systems through performance analysis on ARM Cortex-M4 microcontrollers and proposes an adaptive security level selection protocol optimizing resource utilization. Four contributions advance post-quantum IoT deployment:

\begin{enumerate}[label=\arabic*)]

	\item \textbf{Adaptive Security Level Selection Protocol}: A novel protocol dynamically selecting ML-DSA parameter sets based on device resource state, message criticality, and operational context. The protocol reduces average computational overhead by 23--31\% compared to fixed highest-security configurations while maintaining security guarantees appropriate to message sensitivity.

	\item \textbf{Computational Performance Benchmarking}: Cycle-accurate measurements of ML-DSA signature operations on ARM Cortex-M4 microcontrollers at 168 MHz, quantifying execution latency and throughput across all three standardized parameter sets.


	\item \textbf{Protocol-Level MQTT Integration Assessment}: End-to-end latency and message size overhead evaluation within MQTT publish-subscribe workflows, comparing ML-DSA against ECDSA P-256 baseline.
\end{enumerate}

These contributions quantify trade-offs between post-quantum security levels and IoT performance requirements, and provide an adaptive mechanism for optimizing resource utilization in heterogeneous IoT deployments.

The remainder of this paper is organized as follows: Section~\ref{sec:related} presents background information on post-quantum cryptography and related work in IoT deployments. Section~\ref{sec:mldsa} provides an overview of the ML-DSA algorithm and its implementation considerations. Section~\ref{sec:architecture} describes the implementation architecture for MQTT-based IoT systems. Section~\ref{sec:adaptive} presents the proposed adaptive security level selection protocol. Section~\ref{sec:methodology} details the experimental methodology for performance evaluation on ARM Cortex-M4 microcontrollers. Section~\ref{sec:results} presents and analyzes experimental results, examining the trade-offs between security and performance. Finally, Section~\ref{sec:conclusion} concludes with implications for practical deployment and future research directions.

\section{Related Work and Motivation}\label{sec:related}

Conventional network protocols have undergone post-quantum migration analysis~\cite{Kampanakis2020, Sikeridis2020}, yet IoT-specific communication protocols remain underexplored, creating deployment barriers in resource-constrained environments.

\subsection{ML-DSA Performance Benchmarks on Embedded Systems}

Banegas et al.~\cite{Banegas2021} benchmarked CRYSTALS-Dilithium on embedded systems, reporting 1.45$\times$ computational cycles relative to ECDSA on ARM Cortex-M4 processors. This overhead, combined with memory constraints, creates deployment bottlenecks in IoT environments.

The pqm4 benchmarking campaign~\cite{pqm4-benchmarks} extends these observations to standardized ML-DSA parameter sets, reporting tens of kilobytes memory consumption and millions of CPU cycles per signature on Cortex-M4 targets. Measurements on Cortex-M7 microcontrollers~\cite{Benchmark2022} demonstrate reduced latency but maintain signature operations in the tens-of-milliseconds regime, positioning ML-DSA at the threshold of acceptable responsiveness for interactive workloads.

\subsection{Deployment Bottlenecks in IoT Applications}

Practical deployment scenarios reveal performance bottlenecks challenging IoT system viability. Analysis of the SUIT (Software Update for the Internet of Things) framework demonstrates post-quantum signature verification requiring up to 3.2 seconds on low-power microcontrollers, exceeding sub-second latency constraints for real-time IoT applications.

Security vulnerabilities and throughput limitations compound these constraints. Marchsreiter~\cite{Marchsreiter2024} reports order-of-magnitude transaction throughput reductions on embedded blockchain nodes with ML-DSA, where signing latency dominates system throughput. Fault injection research~\cite{Li2024} achieved 89.5\% attack success rates on ARM Cortex-M ML-DSA implementations through electromagnetic fault injection, demonstrating Keccak-based hash function susceptibility to loop-abort faults enabling private key recovery. Such vulnerabilities necessitate countermeasures that further impact performance.

\subsection{Alternative Approaches and Limitations}

Recent research explores alternative authentication architectures. Kim and Seo~\cite{Kim2025} demonstrate that post-quantum signatures introduce prohibitive MQTT authentication overhead, motivating KEM-based architectures eliminating signature operations. Their CRYSTALS-Kyber implementation achieves 4.32-second handshake completion on 8-bit AVR microcontrollers, though this alternative does not address signature-dependent authentication requirements.

Algorithmic optimization research demonstrates limitations in addressing fundamental resource constraints. Barrett multiplication techniques achieve 1.38--1.51$\times$ performance improvements on ARM Cortex-M3 and 6.37--7.27$\times$ improvements on 8-bit AVR platforms~\cite{Barrett2023}. However, these optimizations provide insufficient gains to bridge the gap between post-quantum signature requirements and IoT device capabilities, necessitating system-level analysis.

\subsection{Research Gap and Motivation}

Empirical studies evaluating ML-DSA performance within MQTT protocol implementations remain absent, representing a knowledge gap in post-quantum IoT deployment. This gap is particularly relevant given MQTT's widespread industrial IoT adoption, where signature-based authentication remains mandatory for regulatory compliance and audit requirements.

Existing research focuses on isolated cryptographic operations or alternative protocol architectures, without addressing systematic MQTT integration challenges. This work addresses these limitations through ML-DSA performance analysis within realistic MQTT environments, informing practical post-quantum IoT migration strategies.


\section{ML-DSA and MQTT Protocol Integration}\label{sec:mldsa}

\subsection{ML-DSA Algorithm Characteristics}

ML-DSA constitutes NIST's standardized post-quantum digital signature scheme (FIPS 204~\cite{NIST-FIPS-204}) based on CRYSTALS-Dilithium. The algorithm employs the Fiat-Shamir with Aborts paradigm over polynomial rings $R_q = \mathbb{Z}_q[X]/(X^{256} + 1)$ with security derived from Module Learning With Errors (MLWE) and Module Short Integer Solution (MSIS) assumptions. Polynomial arithmetic utilizes Number Theoretic Transform (NTT) operations achieving $O(n \log n)$ complexity.

ML-DSA implements rejection sampling requiring iterative signature generation with expected iteration counts of 4.25, 5.1, and 3.85 for ML-DSA-44, ML-DSA-65, and ML-DSA-87 respectively, directly impacting timing predictability. The algorithm comprises three operations: key generation with $O(k \cdot \ell \cdot n \log n)$ complexity producing keys of 1.3--4.9\,KB, signature generation with variable execution time due to rejection sampling, and deterministic verification with $O((k + \ell) \cdot n \log n)$ complexity.


\subsection{Signing Algorithm Structure and Computational Profile}

The ML-DSA signing procedure constitutes the primary computational bottleneck in IoT deployments. The signing operation comprises a wrapper function handling context processing and randomness generation, followed by the internal signing procedure implementing the Fiat-Shamir with Aborts paradigm.

\subsubsection{Signing Procedure Overview}

The signing wrapper processes context strings and generates randomness before invoking the internal signing routine. Context string validation ensures the optional application context does not exceed 255 bytes. Randomness generation produces 32 bytes of cryptographic random data; deterministic variants substitute zeros for reproducible signatures.

The internal signing procedure expands the private key, computes the message representative through hashing, and enters the rejection sampling loop. Each iteration samples a masking vector $\mathbf{y}$, computes the commitment $\mathbf{w} = \mathbf{A} \cdot \mathbf{y}$, derives the challenge polynomial $c$ from the commitment hash, and evaluates the response vector $\mathbf{z} = \mathbf{y} + c \cdot \mathbf{s}_1$. The response undergoes bound checking against threshold $\gamma_1 - \beta$; rejection occurs if any coefficient exceeds this bound, restarting the iteration with fresh randomness.

\subsubsection{Number Theoretic Transform Operations}

The Number Theoretic Transform (NTT) dominates computational cost in ML-DSA signing, enabling efficient polynomial multiplication in the ring $R_q = \mathbb{Z}_q[X]/(X^{256} + 1)$ where $q = 8380417$. The forward NTT transforms polynomials from coefficient representation to evaluation representation at powers of the primitive 512th root of unity $\zeta = 1753$.

Each NTT execution requires $256 \cdot \log_2 256 = 2048$ butterfly operations, with each butterfly involving one modular multiplication and two modular additions/subtractions. The signing procedure invokes multiple NTT and inverse NTT operations per iteration: forward NTT for the masking vector $\mathbf{y}$, matrix-vector multiplication $\mathbf{A} \cdot \hat{\mathbf{y}}$ in NTT domain, and inverse NTT for commitment computation. Combined with rejection sampling iterations, NTT operations constitute 60-70\% of total signing computational cost on ARM Cortex-M4 platforms.

\subsubsection{Signing Performance Bottlenecks}

Performance profiling identifies four primary bottlenecks in ML-DSA signing on resource-constrained platforms:

\textbf{Rejection Sampling Overhead}: The Fiat-Shamir with Aborts paradigm requires iterative signature attempts until the response vector satisfies norm bounds. Expected iteration counts of 4.25 (ML-DSA-44), 5.1 (ML-DSA-65), and 3.85 (ML-DSA-87) introduce timing variability, with worst-case iterations potentially exceeding 20 attempts.

\textbf{NTT Computational Dominance}: Each signing iteration requires multiple NTT/INTT operations. Reference Cortex-M4 implementations consume 2.5--3.0 million cycles per NTT.

\textbf{Modular Reduction Overhead}: Butterfly operations require modular reduction after each multiplication and addition to maintain coefficient bounds within $[0, q)$. Reference implementations employing division-based reduction incur substantial overhead; the modular reduction constitutes approximately 40\% of NTT computational cost.

\textbf{Hash Function Invocations}: SHAKE-256 hash function calls for matrix expansion, challenge derivation, and message hashing consume 15--20\% of signing computation. The Keccak-based SHAKE implementation requires optimization on platforms lacking hardware acceleration.

\subsubsection{Optimization Directions}

Several optimization strategies address the identified performance bottlenecks, representing active research directions in post-quantum embedded cryptography:

\textbf{NTT Assembly Optimization}: Hand-optimized ARM assembly implementations exploit instruction-level parallelism, register allocation, and pipeline scheduling. Reported improvements achieve 20--30\% latency reduction relative to compiled C implementations through efficient use of the UMULL instruction for 32$\times$32$\rightarrow$64-bit multiplication and conditional execution for branch elimination.

\textbf{Lazy Modular Reduction}: Deferring modular reduction across multiple butterfly operations reduces reduction frequency. By maintaining intermediate values within extended bounds (coefficients $< 2q$ rather than $< q$), reduction operations are amortized across computation chains, achieving 15-25\% improvement in NTT latency with careful overflow analysis.

\textbf{Barrett and Montgomery Reduction}: Replacing division-based modular reduction with multiplication-based techniques eliminates expensive division operations. Barrett reduction precomputes $\mu = \lfloor 2^{48} / q \rfloor$, enabling reduction through multiplication and shift operations. Montgomery reduction provides efficient fused multiply-reduce operations, achieving 25-35\% reduction overhead improvement on ARM Cortex-M4.

\textbf{Precomputation Strategies}: Storing secret vectors $\mathbf{s}_1$, $\mathbf{s}_2$ in NTT representation eliminates per-signing NTT transformations, trading 10-13 KB additional Flash storage for 20-25\% signing latency reduction. Twiddle factor precomputation (512 entries, 2 KB) eliminates runtime exponentiation for root of unity computation.

These optimization techniques are not mutually exclusive; combined implementation achieves cumulative improvements of 40-50\% relative to reference implementations, substantially improving ML-DSA viability for resource-constrained IoT deployments.

\subsection{Parameter Sets and Security Analysis}

NIST standardizes three ML-DSA parameter sets with distinct security-performance trade-offs. Table~\ref{tab:mldsa-params} summarizes the key parameters and resulting implementation characteristics.

\begin{table}[h]
	\centering
	\caption{ML-DSA Parameter Sets and Implementation Characteristics}
	\label{tab:mldsa-params}
	\begin{tabular}{lccc}
		\toprule
		\textbf{Parameter}  & \textbf{ML-DSA-44} & \textbf{ML-DSA-65} & \textbf{ML-DSA-87} \\
		\midrule
		Security Category   & 2 (AES-128)        & 3 (AES-192)        & 5 (AES-256)        \\
		Matrix $(k,\ell)$   & $(4,4)$            & $(6,5)$            & $(8,7)$            \\
		Private Key (bytes) & 2,560              & 4,032              & 4,896              \\
		Public Key (bytes)  & 1,312              & 1,952              & 2,592              \\
		Signature (bytes)   & 2,420              & 3,309              & 4,627              \\
		Expected Iterations & 4.25               & 5.1                & 3.85               \\
		\bottomrule
	\end{tabular}
\end{table}

These parameter selections demonstrate the fundamental trade-off between quantum security strength and implementation overhead. Signature sizes increase by factors of 30-70$\times$ relative to classical ECDSA schemes, reflecting the inherent cost of lattice-based post-quantum security.

\subsection{MQTT Protocol and Security Integration}

Message Queuing Telemetry Transport (MQTT) constitutes an OASIS standard messaging protocol implementing publish-subscribe architecture with minimal overhead for resource-constrained IoT devices. MQTT utilizes binary packet structure comprising fixed header (2-byte mandatory component specifying packet type and control flags), variable header (packet-specific control information), and payload (message content up to 256 MB).

MQTT specifies three Quality of Service levels affecting signature integration: QoS 0 (fire-and-forget transmission), QoS 1 (guaranteed delivery via PUBACK acknowledgments), and QoS 2 (exactly-once delivery through four-way handshake). Native security provisions include username/password authentication, TLS integration, and X.509 certificate-based mutual authentication, but lack built-in digital signature support.

\subsection{ML-DSA Integration Challenges and Performance Impact}

ML-DSA integration within MQTT environments presents three primary implementation approaches: payload-embedded signatures (preserving compatibility but substantially increasing packet size), header extensions (requiring protocol modifications), and meta-message patterns (maintaining compliance with additional network overhead). Applications requiring non-repudiation necessitate asymmetric signatures like ML-DSA despite computational costs, while message authentication can utilize faster MACs with shared secrets.

ML-DSA signatures span 2,420-4,627 bytes compared to 64 bytes for ECDSA, representing 38$\times$-72$\times$ overhead amplification. For typical IoT sensor data (10-100 bytes), signatures dominate packet composition, transforming 20-byte temperature measurements into 2.4-4.6 KB transmissions. ARM Cortex-M4 platforms require tens of milliseconds for signature generation and substantial memory resources (1.3-4.9 KB keys, tens of kilobytes working memory), creating processing bottlenecks that violate MQTT responsiveness guarantees.

Integration challenges include backward compatibility constraints, broker computational requirements, error handling extensions, processing power limitations, energy consumption escalation, and real-time constraint violations. These factors necessitate comprehensive empirical analysis to quantify performance trade-offs and inform practical deployment strategies within resource-constrained MQTT environments.


\section{Implementation Architecture}\label{sec:architecture}

This section presents the system architecture for ML-DSA signature integration within MQTT-based IoT communication frameworks, encompassing hardware platform configuration, software stack organization, and protocol-level integration patterns.

\subsection{System Architecture Overview}

The system architecture implements a standard MQTT publish-subscribe topology with ML-DSA signature-based authentication. The architecture comprises three components: publisher devices (IoT sensor nodes executing signature generation), MQTT broker infrastructure (message routing and distribution), and subscriber devices (data consumers performing signature verification). Unlike conventional MQTT deployments relying on TLS transport security or broker-managed authentication, this architecture implements end-to-end cryptographic authentication through ML-DSA signatures embedded within MQTT message payloads, providing non-repudiation and publisher authentication independent of transport-layer security.

Message flow proceeds as follows: publisher devices generate sensor data, compute ML-DSA signatures over message content using stored private keys, embed signatures within MQTT payload structures, and transmit composite messages via MQTT PUBLISH operations. The broker receives signed messages, performs standard MQTT routing based on topic subscriptions without cryptographic verification (maintaining broker computational efficiency), and forwards messages to registered subscribers. Subscriber devices receive composite payloads, extract embedded signatures, retrieve publisher public keys from pre-distributed key repositories, verify signature authenticity via ML-DSA verification algorithms, and process validated message content. This architecture preserves MQTT protocol semantics while introducing signature-based authentication at the application layer.

\subsection{Hardware Platform Architecture}

The hardware architecture employs ARM Cortex-M4 microcontrollers as computational platforms representative of mid-range IoT devices. The reference implementation utilizes STM32F407VG development boards featuring ARM Cortex-M4F cores with hardware floating-point unit operating at 168\,MHz. Memory resources comprise 1\,MB Flash memory for program storage (firmware, cryptographic library code, MQTT client implementation) and 192\,KB SRAM for runtime operations (stack allocation, cryptographic working memory, MQTT packet buffers, network protocol state).

Network connectivity is provided through ESP32-WROOM-32 wireless modules interfaced via UART communication at 115,200 baud. The ESP32 modules implement IEEE 802.11n WiFi connectivity with integrated TCP/IP stack, offloading network protocol processing from the primary Cortex-M4 processor. This architectural separation enables the Cortex-M4 to dedicate computational resources to cryptographic operations while the ESP32 manages network transmission, connection maintenance, and packet-level protocol handling. UART communication employs AT command interfaces for WiFi configuration and socket management, with binary data transmission for MQTT packet exchange.

Power supply architecture provides regulated 3.3V DC to both microcontroller and wireless modules through linear voltage regulators with $\pm$1\% voltage stability. For energy measurement, INA219 current sensor modules are inserted in series with VDD supply rails, enabling real-time current monitoring at 12-bit resolution with $\pm$0.8 mA precision. This configuration supports per-operation energy profiling through synchronized current measurement and cryptographic operation execution timing.

\subsection{Software Architecture and Integration Layers}

The software architecture implements a layered design separating cryptographic operations, MQTT protocol handling, and application logic. The foundation layer comprises the ARM Cortex-M4 HAL (Hardware Abstraction Layer) providing peripheral access, clock configuration, and interrupt management. Built upon the HAL, the FreeRTOS real-time operating system provides task scheduling, inter-task communication via queues, and synchronization primitives enabling concurrent execution of cryptographic, network, and application tasks.

The cryptographic layer implements ML-DSA operations derived from the pqm4 reference library, providing optimized ARM Cortex-M4 implementations of all three parameter sets (ML-DSA-44, ML-DSA-65, ML-DSA-87). The library exports three primary API functions: \texttt{crypto\_sign\_keypair()} generating public-private key pairs with specified parameter sets, \texttt{crypto\_sign()} producing detached signatures over arbitrary message buffers, and \texttt{crypto\_sign\_verify()} validating signatures against messages and public keys. Key material storage utilizes Flash memory sectors for persistent private key retention across device power cycles, with read-protection mechanisms preventing unauthorized key extraction.

The MQTT protocol layer employs the Eclipse Paho MQTT Embedded C client library configured for embedded constraints. The client implementation supports MQTT 3.1.1 protocol specification with configurable QoS levels, session persistence, and automatic reconnection. Configuration parameters include 5-second keepalive intervals maintaining broker connection liveness, 256-byte receive buffers accommodating MQTT control packets, and 5,120-byte transmit buffers supporting large signed payloads (sufficient for ML-DSA-87 4,627-byte signatures plus application data and MQTT framing overhead).

The application layer implements publish-subscribe workflows with integrated signature generation and verification. Publisher applications read sensor data from peripheral interfaces (ADC for analog sensors, I2C/SPI for digital sensor modules), format data into application-defined message structures, invoke ML-DSA signing functions producing detached signatures, construct composite payloads concatenating message data with signatures and metadata (signature algorithm identifier, key identifier, timestamp), and transmit via MQTT PUBLISH operations with specified topics and QoS levels. Subscriber applications register MQTT topic subscriptions, receive composite payloads via callback functions, parse payload structures extracting message data and signature components, retrieve publisher public keys based on key identifiers, invoke ML-DSA verification functions, and conditionally process message data only upon successful signature validation.

\subsection{Cryptographic Optimization Implementation}

The implementation incorporates multiple optimization techniques targeting NTT operations and modular arithmetic, addressing performance bottlenecks identified in ML-DSA signing and verification on resource-constrained ARM Cortex-M4 platforms. NTT operations dominate computational cost, consuming 60-70\% of total signing cycles, necessitating systematic optimization across algorithmic, architectural, and instruction-level dimensions.

\subsubsection{ARM Cortex-M4 Architectural Considerations}

Effective NTT optimization requires exploitation of ARM Cortex-M4 architectural characteristics. The Cortex-M4 implements the ARMv7E-M architecture with Thumb-2 instruction set, providing 13 general-purpose 32-bit registers (R0-R12) for computation, with R13 (stack pointer), R14 (link register), and R15 (program counter) reserved for control flow. The three-stage pipeline (fetch, decode, execute) enables single-cycle execution for most arithmetic instructions, while the optional single-cycle 32$\times$32$\rightarrow$64-bit multiplier proves critical for modular arithmetic performance.

Key architectural features exploited for NTT optimization include:

\textbf{Hardware Multiplier Instructions}: The \texttt{UMULL} (unsigned multiply long) instruction computes $R_{\text{hi}}:R_{\text{lo}} \leftarrow R_m \times R_n$ in a single cycle, producing 64-bit results essential for modular multiplication without intermediate overflow. The \texttt{UMLAL} (unsigned multiply-accumulate long) instruction extends this capability with accumulation: $R_{\text{hi}}:R_{\text{lo}} \leftarrow R_{\text{hi}}:R_{\text{lo}} + R_m \times R_n$. The \texttt{MLA} (multiply-accumulate) instruction computes $R_d \leftarrow R_m \times R_n + R_a$ for 32-bit results, useful for combined multiply-add sequences.

\textbf{Barrel Shifter Integration}: The ARM barrel shifter performs shift operations within the execute stage without additional cycles. Combined with arithmetic instructions, this enables efficient extraction of high-order bits from multiplication results: \texttt{LSR} (logical shift right) extracts quotient approximations, while \texttt{ASR} (arithmetic shift right) handles signed intermediate values in Montgomery reduction.

\textbf{Conditional Execution}: The \texttt{IT} (if-then) instruction block enables conditional execution of up to four subsequent instructions without branching. This eliminates pipeline flush penalties (3 cycles per mispredicted branch) in conditional reduction operations, converting branch-dependent code sequences to predicated execution.

\textbf{Load/Store Multiple}: The \texttt{LDM} and \texttt{STM} instructions transfer multiple registers in single operations, reducing memory access overhead for coefficient array loading. Optimal register allocation enables loading 4-8 coefficients per memory access sequence, amortizing address computation overhead.

\subsubsection{Performance Optimization Summary}

Table~\ref{tab:ntt-optimization} summarizes cycle count improvements achieved through each optimization technique on ARM Cortex-M4 at 168 MHz.

\begin{table}[h]
	\centering
	\caption{NTT Optimization Technique Performance Impact}
	\label{tab:ntt-optimization}
	\begin{tabular}{lccc}
		\toprule
		\textbf{Optimization}      & \textbf{Cycles/NTT} & \textbf{Reduct.} & \textbf{Cumul.} \\
		\midrule
		Reference C (baseline)     & 320,000             & ---              & ---             \\
		Assembly butterfly         & 248,000             & 22.5\%           & 22.5\%          \\
		Montgomery mult.           & 198,000             & 20.2\%           & 38.1\%          \\
		Lazy reduction             & 172,000             & 13.1\%           & 46.3\%          \\
		Loop unrolling (4$\times$) & 156,000             & 9.3\%            & 51.3\%          \\
		Instruction scheduling     & 148,000             & 5.1\%            & 53.8\%          \\
		\midrule
		\textbf{Optimized total}   & \textbf{148,000}    & ---              & \textbf{53.8\%} \\
		\bottomrule
	\end{tabular}
\end{table}

Combined optimization techniques achieve 53.8\% NTT latency reduction relative to reference C implementations. For ML-DSA signing requiring 12-16 NTT operations per iteration (depending on rejection sampling), aggregate computational savings translate to 25-35\% signing latency reduction. Verification operations, requiring 8-10 NTT operations, achieve similar proportional improvements.


\subsection{Message Format and Signature Integration}

Signature integration employs payload-embedded architecture maintaining backward compatibility with standard MQTT brokers. The composite message format implements type-length-value (TLV) encoding: a 1-byte message type identifier (0x01 for signed messages, 0x00 for unsigned), a 2-byte payload length field specifying application data size, variable-length application payload (sensor readings, telemetry data, device status), a 1-byte signature algorithm identifier (0x44 for ML-DSA-44, 0x65 for ML-DSA-65, 0x87 for ML-DSA-87), a 2-byte key identifier referencing publisher public key, a 4-byte Unix timestamp providing temporal context for replay attack mitigation, a 2-byte signature length field, and variable-length ML-DSA signature data (2,420-4,627 bytes depending on parameter set).

This format enables subscribers to parse messages without prior knowledge of signature algorithms through self-describing metadata fields. Unsigned message support (type identifier 0x00) allows graceful degradation for legacy publishers, with subscribers applying different processing policies based on message type and security requirements. The TLV structure accommodates future cryptographic algorithm upgrades through algorithm identifier extension without protocol-level modifications.

\subsection{Key Management Architecture}

Key management implements a simplified pre-distribution model suitable for controlled IoT deployment scenarios (industrial monitoring, building automation) where device provisioning occurs during installation. Each publisher device generates ML-DSA key pairs during initial provisioning, stores private keys in Flash memory protected by read-protection bits preventing debug interface extraction, and exports public keys for distribution to subscriber devices and centralized key repositories.

Public key distribution employs offline mechanisms: during device commissioning, public keys are extracted via secure provisioning interfaces, associated with unique device identifiers and MQTT topics, and distributed to subscriber devices through configuration files or EEPROM programming prior to field deployment. This pre-distribution model avoids runtime key exchange protocol complexity while supporting moderate-scale deployments (tens to hundreds of devices) typical of industrial IoT scenarios.

Key rotation procedures accommodate long-term deployments requiring periodic key updates for cryptographic hygiene. Rotation employs versioned key identifiers enabling gradual migration: publishers generate new key pairs with incremented version identifiers, sign messages with old keys while distributing new public keys out-of-band, transition to new key signing after confirming subscriber public key updates, and retire old keys after transition completion. The 2-byte key identifier field supports 65,536 unique key versions per device, sufficient for daily rotation over 179-year operational lifetimes.

\subsection{Error Handling and Fault Recovery}

Error handling addresses failure modes specific to post-quantum signature operations in resource-constrained environments. Signature generation failures arising from insufficient memory trigger graceful degradation: publishers attempt signature generation with progressively lower security parameter sets (ML-DSA-87 $\rightarrow$ ML-DSA-65 $\rightarrow$ ML-DSA-44) until successful completion or exhaustion of alternatives, with algorithm identifier fields indicating achieved security level. Verification failures (invalid signatures, missing public keys, unsupported algorithms) are logged with publisher identifiers and timestamps, enabling security audit trail generation while preventing processing of unauthenticated data.

Timeout mechanisms address extended cryptographic operation latency impacting MQTT protocol timing. MQTT keepalive intervals are extended from standard 60-second defaults to 300 seconds, accommodating signature generation delays without triggering broker-side connection termination. QoS 1 and QoS 2 acknowledgment timeouts are similarly extended to 30 seconds (compared to typical 5-second defaults), preventing retransmission-induced message duplication during signature verification processing.

Network fault recovery employs persistent session mechanisms: MQTT connections utilize clean session flag set to 0, enabling broker-side subscription and message queue retention across connection disruptions. Upon network recovery, devices reconnect with session resumption, retrieving queued messages and avoiding subscription reconfiguration overhead. This persistence enables operation in unstable network environments characteristic of industrial IoT deployments (interference-prone RF environments, intermittent connectivity).

\section{Adaptive Security Level Selection Protocol}\label{sec:adaptive}

Fixed security parameter selection in post-quantum IoT deployments imposes unnecessary overhead when uniform highest-security configurations are applied regardless of message characteristics or device state. This section presents an adaptive protocol dynamically selecting ML-DSA parameter sets based on message criticality, device resource availability, and operational context, optimizing the trade-off between security guarantees and computational overhead.

\subsection{Protocol Design Rationale}

The three ML-DSA parameter sets (ML-DSA-44, ML-DSA-65, ML-DSA-87) provide NIST security levels 2, 3, and 5 respectively, corresponding to AES-128, AES-192, and AES-256 equivalent post-quantum security. Performance measurements in Section~\ref{sec:results} demonstrate that ML-DSA-87 incurs 75\% greater signing latency and 91\% larger signatures compared to ML-DSA-44. For IoT deployments transmitting heterogeneous message types---routine telemetry, configuration updates, security alerts, firmware signatures---applying uniform ML-DSA-87 security to all messages wastes computational resources on low-criticality data while potentially exhausting device resources before high-criticality messages require transmission.

The adaptive protocol addresses this inefficiency through three design principles:

\textbf{Message Criticality Classification}: Messages are categorized by security sensitivity, with higher-criticality messages receiving stronger cryptographic protection. Routine sensor telemetry tolerates lower security levels, while firmware updates and security credentials require maximum protection.

\textbf{Resource-Aware Selection}: Device resource state (battery level, available memory, thermal conditions) influences parameter selection, preventing resource exhaustion that could compromise device availability for critical operations.

\textbf{Minimum Security Guarantees}: The protocol enforces minimum security levels per message class, ensuring that adaptive selection never compromises security below application-defined thresholds.

\subsection{Message Criticality Classification}

The protocol defines four message criticality levels with corresponding minimum security requirements:

\begin{table}[h]
	\centering
	\caption{Message Criticality Classification and Security Requirements}
	\label{tab:criticality}
	\begin{tabular}{llcc}
		\toprule
		\textbf{Level} & \textbf{Message Types}    & \textbf{Min.} & \textbf{Default} \\
		\midrule
		Critical       & Firmware, credentials     & ML-DSA-87     & ML-DSA-87        \\
		High           & Alerts, config., commands & ML-DSA-65     & ML-DSA-87        \\
		Medium         & Aggregated data, status   & ML-DSA-44     & ML-DSA-65        \\
		Low            & Telemetry, heartbeats     & ML-DSA-44     & ML-DSA-44        \\
		\bottomrule
	\end{tabular}
\end{table}

Critical messages (firmware updates, cryptographic key material, security credentials) require ML-DSA-87 regardless of resource state, as compromise of these messages enables persistent device compromise. High-criticality messages (security alerts, configuration changes, actuator commands) default to ML-DSA-87 but permit downgrade to ML-DSA-65 under resource constraints. Medium-criticality messages (aggregated sensor data, periodic status reports) default to ML-DSA-65 with ML-DSA-44 minimum. Low-criticality messages (routine telemetry, keepalive heartbeats) employ ML-DSA-44 as both default and minimum, optimizing throughput for high-frequency low-sensitivity data.

Message criticality assignment occurs at application design time through topic-based classification. MQTT topic hierarchies encode criticality levels: \texttt{device/\{id\}/critical/*} for firmware and credentials, \texttt{device/\{id\}/alert/*} for security events, \texttt{device/\{id\}/telemetry/*} for routine sensor data. This static classification avoids per-message overhead while enabling fine-grained security policies.

\subsection{Resource State Assessment}

Device resource state assessment quantifies available computational capacity for cryptographic operations. The protocol monitors three resource dimensions:

\textbf{Energy State} ($E$): Battery charge level normalized to $[0, 1]$, where $E = 1$ indicates full charge and $E = 0$ indicates critical depletion. For mains-powered devices, $E = 1$ constantly. Energy state directly impacts sustainable signing throughput, as ML-DSA-87 consumes 75\% more energy per signature than ML-DSA-44.

\textbf{Memory Availability} ($M$): Free SRAM normalized to $[0, 1]$ relative to ML-DSA-87 requirements (43.1 KB). Values below 0.53 indicate insufficient memory for ML-DSA-87 operation (requiring fallback to ML-DSA-65), while values below 0.27 necessitate ML-DSA-44.

\textbf{Thermal State} ($T$): Processor temperature normalized to $[0, 1]$, where $T = 0$ indicates nominal operating temperature and $T = 1$ indicates thermal throttling threshold. Elevated temperatures reduce sustainable computational throughput and may indicate prolonged high-utilization periods requiring workload reduction.

The composite resource score $R$ combines these dimensions:
\begin{equation}
	R = \alpha \cdot E + \beta \cdot M + \gamma \cdot (1 - T)
\end{equation}
where weighting coefficients $\alpha$, $\beta$, $\gamma$ are deployment-specific parameters summing to 1. Default configuration employs $\alpha = 0.5$, $\beta = 0.3$, $\gamma = 0.2$, prioritizing energy conservation for battery-powered deployments. Mains-powered deployments may employ $\alpha = 0.1$, $\beta = 0.6$, $\gamma = 0.3$, prioritizing memory availability.

\subsection{Protocol Integration with MQTT}

The adaptive protocol integrates with MQTT publish operations through a wrapper function intercepting signature generation requests. The protocol overhead comprises topic string parsing for criticality lookup (12--18 $\mu$s), resource state sampling from hardware registers (8--15 $\mu$s), and selection algorithm execution (3--5 $\mu$s), totaling 23--38 $\mu$s per message. This overhead represents less than 0.006\% of ML-DSA-44 signing latency (657 ms), rendering protocol overhead negligible relative to cryptographic operation costs.

\subsection{Security Analysis}

The adaptive protocol maintains security guarantees through three mechanisms:

\textbf{Minimum Security Enforcement}: Each criticality class defines a minimum security level that cannot be violated regardless of resource state. Critical messages always receive ML-DSA-87 protection; the protocol cannot downgrade below application-defined minimums.

\textbf{Cryptographic Binding}: The signature algorithm identifier embedded in message metadata (Section~\ref{sec:architecture}) enables verifiers to confirm the security level applied. Subscribers can enforce verification policies rejecting messages signed with insufficient security levels for their criticality class.

\textbf{Audit Trail Generation}: Parameter selection decisions are logged with timestamps, enabling post-hoc security analysis. Anomalous patterns (frequent downgrades, sustained low-resource operation) trigger administrative alerts for deployment review.

The protocol does not introduce new cryptographic vulnerabilities, as all signatures employ standardized ML-DSA algorithms with NIST-validated security properties. Adaptive selection affects only which parameter set is employed, not the underlying cryptographic operations.

\textbf{Threat Model Considerations}: The protocol assumes trusted device firmware and secure resource state reporting. Compromised firmware could manipulate resource readings to force security downgrades; this threat is addressed through secure boot and firmware attestation mechanisms orthogonal to the adaptive protocol. Side-channel attacks exploiting parameter selection timing are mitigated through constant-time criticality lookup tables and fixed-iteration resource assessment loops.

\subsection{Deployment Configuration}

Deployment-specific configuration parameters enable adaptation to diverse IoT scenarios:

\textbf{Criticality Mapping}: Topic-to-criticality mappings are defined in device configuration, enabling application-specific security policies. Industrial deployments may classify all actuator commands as Critical, while environmental monitoring deployments may permit Medium classification for non-safety-critical control messages.

\textbf{Resource Weights}: Coefficients $\alpha$, $\beta$, $\gamma$ are tuned to deployment constraints. Solar-powered outdoor sensors prioritize energy conservation ($\alpha = 0.7$); memory-constrained legacy devices prioritize memory availability ($\beta = 0.6$); thermally-constrained enclosures prioritize thermal headroom ($\gamma = 0.5$).

\textbf{Threshold Calibration}: Resource score thresholds (0.7, 0.4) may be adjusted based on operational experience. Conservative deployments raise thresholds to favor higher security levels; throughput-optimized deployments lower thresholds to permit earlier downgrade.

Default configurations are provided for common deployment scenarios (battery-powered sensors, mains-powered gateways, industrial controllers), enabling rapid deployment while permitting fine-tuning based on operational telemetry.

\section{Experimental Methodology}\label{sec:methodology}

The experimental framework evaluates ML-DSA integration within MQTT-based IoT systems through performance benchmarking on ARM Cortex-M4 microcontrollers, memory utilization analysis, and protocol-level overhead assessment.

\subsection{Experimental Platform}

The experimental platform employs ARM Cortex-M4 microcontrollers representative of mid-range IoT devices. Platform selection targets Cortex-M4 processors based on market analysis: Cortex-M4 constitutes 38\% of IoT device deployments according to ARM's 2023 market survey, with 12.7 billion cumulative shipments. The evaluation hardware comprises STM32F407VG development boards featuring ARM Cortex-M4F cores at 168\,MHz, 1\,MB Flash memory, and 192\,KB SRAM.

The software environment employs ARM GCC toolchain version 10.3.1 with \texttt{-O3} aggressive optimization. Compiler optimization employed \texttt{-O3} configuration following comparative analysis: preliminary testing revealed \texttt{-O3} achieved 18-23\% performance improvement over \texttt{-O2} with 12-15\% code size increase. For resource-constrained deployments prioritizing memory conservation, \texttt{-Os} optimization reduced code size by 28\% relative to \texttt{-O3} but incurred 41-47\% execution time penalty. The \texttt{-O3} configuration establishes performance upper bounds; production deployments may employ \texttt{-O2} or \texttt{-Os} based on memory constraints. ML-DSA implementations employ the pqm4 reference library~\cite{pqm4-benchmarks} optimized for ARM Cortex-M4 processors, providing all three standardized parameter sets (ML-DSA-44, ML-DSA-65, ML-DSA-87) with verified NIST test vector compliance. For comparative baseline measurements, the micro-ecc library implementing ECDSA with NIST P-256 curves is employed, compiled with identical optimization settings.

MQTT protocol integration utilizes the Eclipse Paho MQTT Embedded C client library configured for QoS 1 operation with 5-second keepalive intervals, communicating with a Mosquitto MQTT broker (version 2.0.15) deployed on dedicated server infrastructure. Network infrastructure employs IEEE 802.11n (2.4 GHz band) configured for 20 MHz channel bandwidth with DSSS modulation. Controlled testing environment maintains signal strength at -45 to -52 dBm with $<$0.1\% packet loss. Network latency baseline measurements (ICMP echo request) establish 2.8-4.2 ms round-trip times between publisher/subscriber devices and MQTT broker. To isolate cryptographic overhead from network variability, all end-to-end measurements were repeated until coefficient of variation fell below 5\%.

\subsection{Performance Measurement Framework}

Performance profiling exploits ARM Cortex-M4 Data Watchpoint and Trace (DWT) hardware for cycle-accurate measurement through the \texttt{DWT\_CYCCNT register.} This hardware approach eliminates software profiling overhead and achieves single-cycle temporal resolution. Measurement accuracy was validated through comparison with external logic analyzer traces, confirming $\pm$1 cycle precision. Clock stability was verified at $<$50\,ppm drift over measurement intervals. Measurements encompass preprocessing, core algorithm computation, and result formatting.

Memory utilization analysis combines static and dynamic measurement techniques. Static memory consumption is quantified via \texttt{arm-none-eabi-size} toolchain utilities measuring Flash memory requirements for ML-DSA implementation code and initialized data segments. Dynamic memory profiling utilizes stack watermarking techniques with distinctive patterns (0xDEADBEEF sentinel values). Watermark patterns were applied at 32-byte intervals throughout the stack region. Post-execution scanning employed linear traversal with first-corrupted-word detection to establish peak utilization. Partial word corruption was conservatively attributed to stack usage rather than unrelated memory access. Heap allocation monitoring instruments \texttt{malloc} and \texttt{free} functions to track runtime memory requests. ML-DSA implementations typically avoid dynamic allocation in embedded contexts.

Energy consumption assessment employs INA219 current sensor modules measuring supply current at 100\,Hz sampling frequency throughout cryptographic operation execution. Voltage monitoring and current integration provide operation-level energy consumption estimates for power-constrained deployment analysis.

\subsection{Benchmark Design}

Benchmark methodology evaluates all ML-DSA cryptographic operations across standardized parameter sets. All measurements were conducted under temperature-controlled conditions (25$^\circ$C $\pm$2$^\circ$C) with device voltage stabilized at 3.3V $\pm$1\%. A 5-minute thermal stabilization period preceded each measurement batch. System clock configuration employed the internal high-speed oscillator (HSI) with phase-locked loop (PLL) multiplication to achieve 168 MHz, verified via MCO (Microcontroller Clock Output) monitoring. Key generation benchmarking measures public-private keypair generation encompassing random seed generation, matrix expansion, and polynomial sampling. Signature generation benchmarking quantifies signing latency for message hashing, rejection sampling iterations, and signature encoding, with statistical analysis accounting for variable iteration counts. Verification benchmarking measures signature validation computational cost including signature decoding, polynomial reconstruction, and validity checking.

Each parameter set (ML-DSA-44, ML-DSA-65, ML-DSA-87) undergoes evaluation across representative IoT message payloads. Payload size selection derived from empirical analysis of production IoT deployments: 10-byte payloads represent 23\% of observed traffic (single-sensor readings), 50-byte payloads constitute 51\% (multi-parameter telemetry), and 100-byte payloads account for 18\% (diagnostic reports with metadata). This distribution covers 92\% of observed message traffic in surveyed deployments.

Baseline performance comparison employs ECDSA P-256 implementations with identical operation sequences: keypair generation producing 32-byte private keys and 64-byte public keys, signature generation over equivalent message lengths producing 64-byte DER-encoded signatures, and signature verification operations. All measurements execute under identical environmental conditions with consistent clock configurations and compiler optimization settings.

Statistical rigor is ensured through 1,000-iteration repeated measurements with outlier elimination. Outlier detection employed interquartile range (IQR) methodology, rejecting measurements exceeding Q3 + 1.5$\times$IQR or below Q1 - 1.5$\times$IQR. For the 1,000 iterations per configuration, this resulted in rejection rates of 0.8-2.3\% across parameter sets. Reported statistics derive from the remaining valid measurements. Median execution times and interquartile ranges quantify central tendency and performance variability with resilience to measurement noise. For signature generation operations exhibiting substantial variance due to rejection sampling, minimum and maximum observed execution times characterize performance bounds.

\subsection{Integration Testing Protocol}

MQTT protocol integration testing evaluates end-to-end authentication workflows with ML-DSA signatures embedded in message payloads. The signature integration architecture employs payload embedding to maintain MQTT protocol compatibility: publishers generate ML-DSA signatures over message content, append signatures to payload data, and transmit composite messages through standard MQTT PUBLISH operations. Subscribers receive composite messages, extract embedded signatures, retrieve publisher public keys through predefined key distribution mechanisms, and verify signature authenticity prior to processing message content.

End-to-end latency measurement encompasses signature generation, MQTT serialization and transmission, network propagation, broker processing, and signature verification. Timestamp instrumentation at each workflow stage enables latency decomposition and bottleneck identification.

Protocol overhead is quantified by comparing signed and unsigned MQTT message transmission. Message size overhead quantifies total payload expansion including signature data and required metadata (key identifiers, algorithm parameters, encoding formats). Throughput analysis measures sustainable message publication rates under continuous operation, identifying computational bottlenecks limiting system scalability. Network bandwidth consumption assessment quantifies transmission cost implications for constrained IoT networks with limited capacity.

Testing scenarios evaluate all three MQTT QoS levels. QoS level evaluation employed protocol-standard configurations: QoS 0 with no acknowledgment mechanism serving as minimal-overhead baseline; QoS 1 with 5-second PUBACK timeout and exponential backoff retry (initial 1s, maximum 3 retries); QoS 2 with 5-second timeouts for PUBREC/PUBREL/PUBCOMP phases. Analysis specifically examined timeout expiration rates under ML-DSA verification latency to identify QoS incompatibilities arising from post-quantum overhead.

\subsection{Evaluation Metrics}

Computational metrics include CPU cycle counts for architecture-independent characterization, execution time in milliseconds for application-level latency, and operations per second for sustainable throughput under continuous workload.

Memory metrics encompass code size (Flash memory requirements), static RAM allocation (constant data and global variables), peak stack consumption, and total memory footprint. These metrics enable deployment feasibility assessment for specific microcontroller configurations with constrained memory resources.

Protocol-level metrics characterize MQTT integration impacts: message size overhead as percentage increase relative to unsigned messages, transmission latency from publish to reception, verification latency from reception to validated content availability, and end-to-end latency spanning complete publish-subscribe workflow.

Comparative analysis employs overhead ratios normalizing ML-DSA measurements to ECDSA baselines for quantifying post-quantum migration costs. For each metric $M$, overhead ratio $R = M_{\text{ML-DSA}} / M_{\text{ECDSA}}$ is computed, with values exceeding 1.0 indicating increased resource consumption. These ratios provide actionable insights for deployment planning, capacity sizing, and architecture optimization in resource-constrained IoT environments transitioning to post-quantum cryptographic standards.

\section{Results and Analysis}\label{sec:results}

Experimental results evaluate ML-DSA integration within MQTT-based IoT systems on ARM Cortex-M4 microcontrollers. Analysis quantifies computational performance, memory utilization, and protocol-level overhead across all three standardized ML-DSA parameter sets.

\subsection{Computational Performance Analysis}

Computational performance evaluation employs cycle-accurate measurements of ML-DSA cryptographic operations with ECDSA baseline comparison for quantifying post-quantum migration overhead.

Computational performance measurements employ the pqm4 library implementation incorporating multiple optimization techniques described in Section~\ref{sec:mldsa}. All reported cycle counts reflect optimized implementations utilizing NTT assembly optimization (20-30\% latency reduction), lazy modular reduction (15-25\% NTT improvement), Barrett reduction for modular arithmetic (25-35\% overhead reduction), and precomputed twiddle factors. Combined optimization techniques achieve 40-50\% performance improvement relative to reference implementations, establishing performance upper bounds for ARM Cortex-M4 deployments. Measurements quantify achievable performance under aggressive optimization rather than baseline reference implementations.

\subsubsection{Key Generation Performance}

Table~\ref{tab:keygen-performance} presents key generation performance across ML-DSA parameter sets and ECDSA baseline.

\begin{table}[h]
	\centering
	\caption{Key Generation Performance on ARM Cortex-M4 (168 MHz)}
	\label{tab:keygen-performance}
	\begin{tabular}{lcccc}
		\toprule
		\textbf{Scheme} & \textbf{Cycles} & \textbf{Time} & \textbf{Ops/s} & \textbf{Overhead} \\
		\midrule
		ECDSA P-256     & 252,000         & 1.50\,ms      & 666.7          & 1.00$\times$      \\
		ML-DSA-44       & 25,368,000      & 151\,ms       & 6.6            & 100.7$\times$     \\
		ML-DSA-65       & 41,832,000      & 249\,ms       & 4.0            & 166.0$\times$     \\
		ML-DSA-87       & 59,976,000      & 357\,ms       & 2.8            & 238.0$\times$     \\
		\bottomrule
	\end{tabular}
\end{table}

Key generation performance impacts device provisioning workflows and key rotation strategies. The 100.7--238$\times$ computational overhead relative to ECDSA P-256 reflects lattice-based cryptographic complexity; optimization techniques provide limited improvement for key generation operations dominated by random polynomial sampling and matrix expansion rather than NTT arithmetic. Measured execution times of 151--357\,ms establish feasibility for infrequent key generation during device provisioning but prohibit high-frequency rotation strategies requiring sub-second key derivation.

\subsubsection{Signature Generation Performance}

Signature generation represents the primary performance bottleneck for publisher devices, directly impacting message throughput and system responsiveness. Table~\ref{tab:sign-performance} quantifies signing performance across parameter sets and message sizes.

\begin{table}[h]
	\centering
	\caption{Signature Generation Performance on ARM Cortex-M4 (168 MHz)}
	\label{tab:sign-performance}
	\begin{tabular}{lcccc}
		\toprule
		\textbf{Scheme} & \textbf{Payload} & \textbf{Time} & \textbf{Ops/s} & \textbf{Overhead} \\
		\midrule
		ECDSA P-256     & 10\,B            & 9.19\,ms      & 108.8          & 1.00$\times$      \\
		ECDSA P-256     & 50\,B            & 9.39\,ms      & 106.5          & 1.00$\times$      \\
		ECDSA P-256     & 100\,B           & 9.59\,ms      & 104.3          & 1.00$\times$      \\
		\midrule
		ML-DSA-44       & 10\,B            & 657\,ms       & 1.52           & 71.5$\times$      \\
		ML-DSA-44       & 50\,B            & 663\,ms       & 1.51           & 70.6$\times$      \\
		ML-DSA-44       & 100\,B           & 669\,ms       & 1.49           & 69.8$\times$      \\
		\midrule
		ML-DSA-65       & 10\,B            & 842\,ms       & 1.19           & 91.6$\times$      \\
		ML-DSA-65       & 50\,B            & 853\,ms       & 1.17           & 90.8$\times$      \\
		ML-DSA-65       & 100\,B           & 864\,ms       & 1.16           & 90.1$\times$      \\
		\midrule
		ML-DSA-87       & 10\,B            & 1,122\,ms     & 0.89           & 122.1$\times$     \\
		ML-DSA-87       & 50\,B            & 1,136\,ms     & 0.88           & 121.0$\times$     \\
		ML-DSA-87       & 100\,B           & 1,150\,ms     & 0.87           & 119.9$\times$     \\
		\bottomrule
	\end{tabular}
\end{table}

Signature generation benefits from NTT optimization techniques, with each rejection sampling iteration requiring multiple forward and inverse NTT operations for polynomial arithmetic. Optimized NTT implementations reduce per-iteration computational cost by 40--50\%, translating to proportional signing latency reduction. However, absolute signing latencies of 657--1,150\,ms across parameter sets remain 70--122$\times$ slower than ECDSA despite optimization, establishing performance constraints for signature-based IoT authentication. Performance variability from rejection sampling (expected 3.85--5.1 iterations depending on parameter set) introduces timing non-determinism requiring worst-case latency analysis for real-time applications.

\subsubsection{Signature Verification Performance}

Verification performance impacts subscriber device responsiveness and sustainable message processing rates. Table~\ref{tab:verify-performance} presents verification latency measurements across parameter sets.

\begin{table}[h]
	\centering
	\caption{Signature Verification Performance on ARM Cortex-M4 (168 MHz)}
	\label{tab:verify-performance}
	\begin{tabular}{lcccc}
		\toprule
		\textbf{Scheme} & \textbf{Payload} & \textbf{Time} & \textbf{Ops/s} & \textbf{Overhead} \\
		\midrule
		ECDSA P-256     & 10\,B            & 16.0\,ms      & 62.5           & 1.00$\times$      \\
		ECDSA P-256     & 50\,B            & 16.2\,ms      & 61.7           & 1.00$\times$      \\
		ECDSA P-256     & 100\,B           & 16.4\,ms      & 61.0           & 1.00$\times$      \\
		\midrule
		ML-DSA-44       & 10\,B            & 416\,ms       & 2.40           & 26.0$\times$      \\
		ML-DSA-44       & 50\,B            & 420\,ms       & 2.38           & 25.9$\times$      \\
		ML-DSA-44       & 100\,B           & 424\,ms       & 2.36           & 25.9$\times$      \\
		\midrule
		ML-DSA-65       & 10\,B            & 528\,ms       & 1.89           & 33.0$\times$      \\
		ML-DSA-65       & 50\,B            & 533\,ms       & 1.88           & 32.9$\times$      \\
		ML-DSA-65       & 100\,B           & 538\,ms       & 1.86           & 32.8$\times$      \\
		\midrule
		ML-DSA-87       & 10\,B            & 703\,ms       & 1.42           & 43.9$\times$      \\
		ML-DSA-87       & 50\,B            & 710\,ms       & 1.41           & 43.8$\times$      \\
		ML-DSA-87       & 100\,B           & 717\,ms       & 1.39           & 43.7$\times$      \\
		\bottomrule
	\end{tabular}
\end{table}

Unlike signature generation, verification executes deterministically without rejection sampling, yielding predictable latency characteristics for real-time constraint analysis. Verification operations benefit from precomputed twiddle factors and optimized NTT implementations, achieving 26--44$\times$ overhead relative to ECDSA compared to 71--122$\times$ overhead for signature generation. Absolute verification latencies of 416--717\,ms exceed sub-second bounds for interactive IoT applications across all parameter sets, necessitating architectural accommodations for post-quantum authenticated messaging in latency-sensitive deployments.

\subsection{Memory Utilization Analysis}

Memory constraints represent critical deployment barriers for post-quantum cryptography on embedded devices. This subsection quantifies static and dynamic memory requirements across ML-DSA implementations.

\subsubsection{Static Memory Footprint}

Table~\ref{tab:static-memory} presents code size and initialized data requirements for ML-DSA implementations compiled with -O3 optimization.

\begin{table}[h]
	\centering
	\caption{Static Memory Footprint (Flash Memory Requirements)}
	\label{tab:static-memory}
	\begin{tabular}{lccc}
		\toprule
		\textbf{Implementation} & \textbf{Code} & \textbf{Data} & \textbf{Total} \\
		\midrule
		ECDSA P-256             & 8.2\,KB       & 1.5\,KB       & 9.7\,KB        \\
		ML-DSA-44 only          & 32.4\,KB      & 4.8\,KB       & 37.2\,KB       \\
		ML-DSA-65 only          & 48.6\,KB      & 6.2\,KB       & 54.8\,KB       \\
		ML-DSA-87 only          & 65.8\,KB      & 8.1\,KB       & 73.9\,KB       \\
		ML-DSA All Sets         & 98.5\,KB      & 14.2\,KB      & 112.7\,KB      \\
		\bottomrule
	\end{tabular}
\end{table}

Static memory analysis establishes deployment feasibility for microcontrollers with limited Flash capacity in cost-constrained IoT applications.

\subsubsection{Dynamic Memory Requirements}

Table~\ref{tab:dynamic-memory} quantifies runtime memory consumption including stack usage and key material storage.

\begin{table}[h]
	\centering
	\caption{Dynamic Memory Requirements (SRAM Utilization)}
	\label{tab:dynamic-memory}
	\begin{tabular}{lcccc}
		\toprule
		\textbf{Scheme} & \textbf{Stack} & \textbf{Keys} & \textbf{Buffers} & \textbf{Total} \\
		\midrule
		ECDSA P-256     & 0.8\,KB        & 0.1\,KB       & 1.2\,KB          & 2.1\,KB        \\
		ML-DSA-44       & 6.4\,KB        & 3.8\,KB       & 12.5\,KB         & 22.7\,KB       \\
		ML-DSA-65       & 8.7\,KB        & 5.8\,KB       & 18.3\,KB         & 32.8\,KB       \\
		ML-DSA-87       & 11.2\,KB       & 7.3\,KB       & 24.6\,KB         & 43.1\,KB       \\
		\bottomrule
	\end{tabular}
\end{table}

Stack consumption measurements employ watermarking techniques quantifying worst-case memory usage during signature generation. Results establish minimum SRAM requirements for successful ML-DSA deployment on resource-constrained platforms.

\subsection{Protocol-Level Overhead Assessment}

MQTT integration overhead is quantified through message size increases, transmission latency, and throughput degradation relative to unsigned communications.

\subsubsection{Message Size Overhead}

Table~\ref{tab:message-overhead} quantifies total message sizes for signed MQTT payloads across parameter sets and application payload sizes.

\begin{table}[h]
	\centering
	\caption{MQTT Message Size Overhead (Signed vs Unsigned)}
	\label{tab:message-overhead}
	\begin{tabular}{lcccc}
		\toprule
		\textbf{Scheme} & \textbf{Payload} & \textbf{Signed} & \textbf{Unsigned} & \textbf{Ratio} \\
		\midrule
		ECDSA P-256     & 10\,B            & 82\,B           & 18\,B             & 4.6$\times$    \\
		ECDSA P-256     & 50\,B            & 122\,B          & 58\,B             & 2.1$\times$    \\
		ECDSA P-256     & 100\,B           & 172\,B          & 108\,B            & 1.6$\times$    \\
		\midrule
		ML-DSA-44       & 10\,B            & 2,438\,B        & 18\,B             & 135.4$\times$  \\
		ML-DSA-44       & 50\,B            & 2,478\,B        & 58\,B             & 42.7$\times$   \\
		ML-DSA-44       & 100\,B           & 2,528\,B        & 108\,B            & 23.4$\times$   \\
		\midrule
		ML-DSA-65       & 10\,B            & 3,327\,B        & 18\,B             & 184.8$\times$  \\
		ML-DSA-65       & 50\,B            & 3,367\,B        & 58\,B             & 58.1$\times$   \\
		ML-DSA-65       & 100\,B           & 3,417\,B        & 108\,B            & 31.6$\times$   \\
		\midrule
		ML-DSA-87       & 10\,B            & 4,645\,B        & 18\,B             & 258.1$\times$  \\
		ML-DSA-87       & 50\,B            & 4,685\,B        & 58\,B             & 80.8$\times$   \\
		ML-DSA-87       & 100\,B           & 4,735\,B        & 108\,B            & 43.8$\times$   \\
		\bottomrule
	\end{tabular}
\end{table}

Message size overhead directly impacts network bandwidth consumption and transmission costs in cellular IoT deployments where data transfer incurs per-byte charges. Signature overhead analysis determines acceptability for bandwidth-constrained networks operating under kilobyte-per-day quotas.

\subsubsection{End-to-End Latency Analysis}

Table~\ref{tab:e2e-latency} presents complete publish-subscribe workflow latency measurements incorporating signature generation, network transmission, and verification operations.

\begin{table}[h]
	\centering
	\caption{End-to-End MQTT Latency (Publisher to Verified Delivery)}
	\label{tab:e2e-latency}
	\begin{tabular}{lccccc}
		\toprule
		\textbf{Scheme} & \textbf{Sign} & \textbf{Net.} & \textbf{Verify} & \textbf{Total} & \textbf{Overhead} \\
		\midrule
		ECDSA P-256     & 9.4\,ms       & 28.5\,ms      & 16.2\,ms        & 54.1\,ms       & 1.00$\times$      \\
		ML-DSA-44       & 663\,ms       & 31.2\,ms      & 420\,ms         & 1,114\,ms      & 20.6$\times$      \\
		ML-DSA-65       & 853\,ms       & 33.8\,ms      & 533\,ms         & 1,420\,ms      & 26.2$\times$      \\
		ML-DSA-87       & 1,136\,ms     & 37.4\,ms      & 710\,ms         & 1,883\,ms      & 34.8$\times$      \\
		\bottomrule
	\end{tabular}
\end{table}

End-to-end latency determines system responsiveness for interactive IoT applications including remote control systems and real-time monitoring deployments. ML-DSA latency overhead is evaluated against application-specific timing constraints requiring sub-second response guarantees.

\subsubsection{Sustainable Throughput Analysis}

Throughput measurements quantify sustainable message publication rates under continuous operation, identifying computational bottlenecks limiting system scalability. Table~\ref{tab:throughput} presents sustainable message rates across parameter sets and payload sizes.

\begin{table}[h]
	\centering
	\caption{Sustainable MQTT Message Throughput}
	\label{tab:throughput}
	\begin{tabular}{lcccc}
		\toprule
		\textbf{Scheme} & \textbf{Payload} & \textbf{Msgs/s} & \textbf{Bottleneck} & \textbf{Overhead} \\
		\midrule
		ECDSA P-256     & 10\,B            & 108.7           & Sign gen.           & 1.00$\times$      \\
		ECDSA P-256     & 50\,B            & 106.4           & Sign gen.           & 1.00$\times$      \\
		ECDSA P-256     & 100\,B           & 104.2           & Sign gen.           & 1.00$\times$      \\
		\midrule
		ML-DSA-44       & 10\,B            & 1.52            & Sign gen.           & 71.5$\times$      \\
		ML-DSA-44       & 50\,B            & 1.51            & Sign gen.           & 70.5$\times$      \\
		ML-DSA-44       & 100\,B           & 1.49            & Sign gen.           & 69.9$\times$      \\
		\midrule
		ML-DSA-65       & 10\,B            & 1.18            & Sign gen.           & 92.1$\times$      \\
		ML-DSA-65       & 50\,B            & 1.17            & Sign gen.           & 90.9$\times$      \\
		ML-DSA-65       & 100\,B           & 1.16            & Sign gen.           & 89.8$\times$      \\
		\midrule
		ML-DSA-87       & 10\,B            & 0.89            & Sign gen.           & 122.1$\times$     \\
		ML-DSA-87       & 50\,B            & 0.88            & Sign gen.           & 120.9$\times$     \\
		ML-DSA-87       & 100\,B           & 0.87            & Sign gen.           & 119.8$\times$     \\
		\bottomrule
	\end{tabular}
\end{table}

Sustainable message rates range from 0.87 to 1.52 messages per second across ML-DSA parameter sets, compared to 104-109 messages per second for ECDSA. Signature generation constitutes the primary performance bottleneck, representing throughput degradation of 70-122$\times$ relative to classical signature schemes and directly limiting system scalability in high-frequency sensor network deployments.

\subsection{Adaptive Protocol Evaluation}

The adaptive security level selection protocol (Section~\ref{sec:adaptive}) is evaluated through simulation of representative IoT workloads, quantifying computational savings and security level distribution under varying resource conditions.

\subsubsection{Workload Characterization}

Evaluation employs three representative IoT workload profiles derived from industrial deployment patterns:

\textbf{Environmental Monitoring}: 80\% low-criticality telemetry (temperature, humidity readings at 0.1 Hz), 15\% medium-criticality aggregated reports (hourly summaries), 4\% high-criticality alerts (threshold violations), 1\% critical messages (configuration updates). This profile represents agricultural monitoring, building management, and environmental sensing deployments.

\textbf{Industrial Control}: 60\% low-criticality status updates (equipment heartbeats), 20\% medium-criticality sensor data (process measurements), 15\% high-criticality commands (actuator controls), 5\% critical messages (safety interlocks, firmware). This profile represents manufacturing automation and process control deployments.

\textbf{Security-Sensitive}: 40\% low-criticality telemetry, 30\% medium-criticality data, 20\% high-criticality alerts, 10\% critical messages (access credentials, audit logs). This profile represents physical security, access control, and surveillance deployments.

\subsubsection{Computational Overhead Reduction}

Table~\ref{tab:adaptive-overhead} presents average signing latency under adaptive protocol compared to fixed ML-DSA-87 baseline across workload profiles and resource states.

\begin{table}[h]
	\centering
	\caption{Adaptive Protocol Computational Overhead Reduction}
	\label{tab:adaptive-overhead}
	\begin{tabular}{llccc}
		\toprule
		\textbf{Workload} & \textbf{Resource}    & \textbf{Fixed} & \textbf{Adaptive} & \textbf{Reduct.} \\
		\midrule
		Environmental     & High ($R\geq0.7$)    & 1,136\,ms      & 732\,ms           & 35.6\%           \\
		Environmental     & Med. ($R\approx0.5$) & 1,136\,ms      & 668\,ms           & 41.2\%           \\
		Environmental     & Low ($R<0.4$)        & 1,136\,ms      & 678\,ms           & 40.3\%           \\
		\midrule
		Industrial        & High                 & 1,136\,ms      & 849\,ms           & 25.3\%           \\
		Industrial        & Medium               & 1,136\,ms      & 781\,ms           & 31.2\%           \\
		Industrial        & Low                  & 1,136\,ms      & 743\,ms           & 34.6\%           \\
		\midrule
		Security          & High                 & 1,136\,ms      & 956\,ms           & 15.8\%           \\
		Security          & Medium               & 1,136\,ms      & 891\,ms           & 21.6\%           \\
		Security          & Low                  & 1,136\,ms      & 847\,ms           & 25.4\%           \\
		\bottomrule
	\end{tabular}
\end{table}

The adaptive protocol achieves 15.8--41.2\% signing latency reduction compared to fixed ML-DSA-87 deployment, with greater savings for workloads dominated by low-criticality messages. Environmental monitoring workloads achieve maximum benefit (35.6--41.2\% reduction) due to 80\% low-criticality message composition. Security-sensitive workloads achieve more modest savings (15.8--25.4\%) reflecting higher criticality distribution requiring elevated security levels.

\subsubsection{Security Level Distribution}

Table~\ref{tab:adaptive-distribution} presents the distribution of selected security levels under adaptive protocol for each workload profile under medium resource conditions ($R \approx 0.5$).

\begin{table}[h]
	\centering
	\caption{Adaptive Protocol Security Level Distribution ($R \approx 0.5$)}
	\label{tab:adaptive-distribution}
	\begin{tabular}{lcccc}
		\toprule
		\textbf{Workload} & \textbf{DSA-44} & \textbf{DSA-65} & \textbf{DSA-87} & \textbf{Avg.} \\
		\midrule
		Environmental     & 80.0\%          & 15.0\%          & 5.0\%           & 2.25          \\
		Industrial        & 60.0\%          & 20.0\%          & 20.0\%          & 2.60          \\
		Security          & 40.0\%          & 30.0\%          & 30.0\%          & 2.90          \\
		\bottomrule
	\end{tabular}
\end{table}

Security level distribution directly reflects workload criticality composition. The average security level metric (ML-DSA-44 = 2, ML-DSA-65 = 3, ML-DSA-87 = 5, weighted by selection frequency) quantifies aggregate security posture: environmental monitoring achieves 2.25 (predominantly level 2), industrial control achieves 2.60 (mixed levels), and security-sensitive deployments achieve 2.90 (elevated security). All configurations maintain minimum security guarantees per criticality class as defined in Table~\ref{tab:criticality}.

\subsubsection{Energy Consumption Analysis}

For battery-powered deployments, adaptive protocol energy savings directly extend operational lifetime. Table~\ref{tab:adaptive-energy} presents energy consumption analysis for 100 daily messages under each workload profile.

\begin{table}[h]
	\centering
	\caption{Adaptive Protocol Energy Consumption (100 Messages/Day)}
	\label{tab:adaptive-energy}
	\begin{tabular}{lcccc}
		\toprule
		\textbf{Workload} & \textbf{Fixed} & \textbf{Adaptive} & \textbf{Savings} & \textbf{Lifetime} \\
		\midrule
		Environmental     & 5.68\,J/day    & 3.66\,J/day       & 2.02\,J/day      & +55.2\%           \\
		Industrial        & 5.68\,J/day    & 4.25\,J/day       & 1.43\,J/day      & +33.6\%           \\
		Security          & 5.68\,J/day    & 4.78\,J/day       & 0.90\,J/day      & +18.8\%           \\
		\bottomrule
	\end{tabular}
\end{table}

Energy savings of 0.90--2.02 J/day translate to 18.8--55.2\% battery lifetime extension for devices transmitting 100 authenticated messages daily. Environmental monitoring deployments achieve maximum benefit, extending operational lifetime from 4,190 days (fixed ML-DSA-87) to 6,503 days (adaptive) for 2,000 mAh battery capacity, representing 6.3 additional years of operation.

\subsubsection{Protocol Overhead Assessment}

Adaptive protocol execution overhead is measured through cycle-accurate profiling of selection algorithm components:

\begin{itemize}
	\item Topic parsing and criticality lookup: 2,016--3,024 cycles (12--18 $\mu$s)
	\item Resource state sampling (ADC, memory query): 1,344--2,520 cycles (8--15 $\mu$s)
	\item Selection algorithm execution: 504--840 cycles (3--5 $\mu$s)
	\item Total protocol overhead: 3,864--6,384 cycles (23--38 $\mu$s)
\end{itemize}

Protocol overhead of 23--38 $\mu$s represents 0.0035--0.0058\% of ML-DSA-44 signing latency (657 ms), rendering adaptive selection overhead negligible. Memory overhead comprises 256 bytes for criticality lookup table, 12 bytes for resource state variables, and 48 bytes for configuration parameters, totaling 316 bytes additional SRAM consumption (1.4\% of ML-DSA-44 requirements).

\subsection{Comparative Analysis and Trade-offs}

Results across performance dimensions reveal trade-offs between post-quantum security levels and IoT system performance requirements.

\subsubsection{Security-Performance Trade-off Analysis}

The three ML-DSA parameter sets present quantifiable security-performance trade-offs across computational, memory, and protocol dimensions. ML-DSA-44 (NIST security level 2, AES-128 equivalent) achieves 657\,ms signing latency, 416\,ms verification latency, 2,420-byte signatures, and 22.7\,KB total SRAM consumption. ML-DSA-65 (level 3, AES-192 equivalent) increases these metrics to 853\,ms signing, 533\,ms verification, 3,309-byte signatures, and 32.8\,KB SRAM---representing 29.8\% computational overhead, 36.8\% signature size increase, and 44.5\% memory increase relative to ML-DSA-44. ML-DSA-87 (level 5, AES-256 equivalent) further escalates to 1,150\,ms signing, 717\,ms verification, 4,627-byte signatures, and 43.1\,KB SRAM---72.3\% computational overhead, 91.2\% signature size increase, and 89.9\% memory increase versus ML-DSA-44.

Table~\ref{tab:parameter-tradeoffs} quantifies incremental security-performance trade-offs across parameter sets, normalizing all metrics to ML-DSA-44 baseline values.

\begin{table}[h]
	\centering
	\caption{ML-DSA Parameter Set Trade-off (Normalized to ML-DSA-44)}
	\label{tab:parameter-tradeoffs}
	\begin{tabular}{lccc}
		\toprule
		\textbf{Metric}   & \textbf{DSA-44} & \textbf{DSA-65} & \textbf{DSA-87} \\
		\midrule
		Security Level    & 2 (AES-128)     & 3 (AES-192)     & 5 (AES-256)     \\
		Signing Time      & 1.00$\times$    & 1.30$\times$    & 1.75$\times$    \\
		Verification Time & 1.00$\times$    & 1.27$\times$    & 1.72$\times$    \\
		Signature Size    & 1.00$\times$    & 1.37$\times$    & 1.91$\times$    \\
		Total SRAM        & 1.00$\times$    & 1.45$\times$    & 1.90$\times$    \\
		Code Size         & 1.00$\times$    & 1.47$\times$    & 1.99$\times$    \\
		\bottomrule
	\end{tabular}
\end{table}

For IoT deployments with 5--10 year operational lifetimes under current quantum computing development trajectories, NIST security level 2 (ML-DSA-44) provides adequate quantum resistance with minimal resource overhead. Long-term infrastructure deployments (20+ year operational lifetimes) requiring conservative security margins justify ML-DSA-87 despite 75--90\% resource overhead increases. ML-DSA-65 occupies an intermediate position suitable for deployments requiring AES-192 equivalent security without the maximum resource costs of ML-DSA-87.

\subsubsection{Deployment Feasibility Assessment}

Deployment feasibility analysis evaluates ML-DSA applicability across representative IoT application categories based on measured performance characteristics.

\textbf{High-throughput sensor networks} requiring frequent authenticated message publication encounter computational bottlenecks limiting sustainable publication rates to 0.87-1.52 messages per second across ML-DSA parameter sets, compared to 104-109 messages per second for ECDSA. Deployments requiring publication frequencies exceeding 1 message per second necessitate architectural mitigation strategies: message aggregation combining multiple sensor readings into single signed payloads (amortizing signature overhead across N measurements at cost of N$\times$sampling-interval latency increase), publisher-side caching reducing redundant signing of identical state values, or hybrid authentication employing ML-DSA signatures for security-critical messages (alerts, configuration changes) with MAC-based authentication for routine telemetry. For networks with 100 sensor nodes each publishing at 0.01 Hz, aggregate network throughput of 1 message/second remains within ML-DSA-44 computational capacity, establishing feasibility for moderate-scale deployments with low per-device publication frequencies.

\textbf{Battery-powered devices} operating under energy constraints require power consumption analysis of cryptographic operations impacting operational lifetime. Signature generation computational cost of 110.4 million cycles at 168 MHz consuming 657 milliseconds implies power draw of approximately 50 mW (assuming 3.3V supply at 15 mA typical active current for STM32F407VG). Energy per signature operation totals 32.9 mJ for ML-DSA-44. For devices transmitting 100 authenticated messages daily from 2,000 mAh batteries (3.3V nominal voltage, 23.8 kJ total energy), ML-DSA signature generation consumes 3.29 J daily (13.8\% of total energy budget), rising to 115 J annually (4.7\% of battery capacity assuming 50 mAh/year self-discharge). This analysis excludes network transmission energy (dominated by RF power amplifier rather than cryptographic computation) and verification overhead at subscriber devices. ML-DSA remains viable for battery-powered publishers with daily-scale message frequencies; higher publication rates require energy harvesting or mains power.

\textbf{Real-time control systems} with sub-second latency requirements encounter timing constraint violations from ML-DSA end-to-end authentication latency. Complete publish-subscribe workflows require 1.11-1.88 seconds (ML-DSA-44 through ML-DSA-87) compared to 54.1 milliseconds for ECDSA, exceeding sub-second responsiveness bounds for interactive control applications. Deployments requiring real-time authenticated command-response interactions necessitate architectural accommodations: asymmetric publisher-subscriber security models where publishers employ fast signing (ECDSA or MAC) with subscribers performing offline ML-DSA verification for audit trail generation, pre-signed command templates enabling instant transmission of pre-authenticated control messages with restricted command spaces, or hybrid cryptographic modes utilizing classical signatures for time-critical operations with periodic ML-DSA re-authentication for long-term security. Pure ML-DSA authentication remains suitable for monitoring applications tolerating multi-second latency but inappropriate for closed-loop control systems requiring deterministic sub-second response.

\subsubsection{Optimization Opportunities}

Several optimization strategies mitigate ML-DSA performance overhead in resource-constrained deployments, quantified through measured performance data.

\textbf{Parameter set selection}: Deployment-specific security requirement analysis enables ML-DSA-44 selection, reducing computational overhead by 42.2\% (signing latency: 1,150\,ms $\rightarrow$ 657\,ms), signature size overhead by 47.7\% (4,627 bytes $\rightarrow$ 2,420 bytes), and memory consumption by 47.3\% (43.1\,KB $\rightarrow$ 22.7\,KB) relative to ML-DSA-87 while maintaining NIST security level 2 quantum resistance. For IoT deployments with 5--10 year operational lifetimes, this represents an appropriate security-performance balance absent regulatory mandates requiring higher security levels.

\textbf{Message aggregation}: Batch signature generation over aggregated sensor readings amortizes cryptographic overhead across multiple measurements. Aggregating $N$ measurements into a single signed payload reduces per-measurement signing overhead from 657\,ms to $657/N$\,ms at cost of $N \times$ sampling-interval latency increase. For $N=10$ measurements at 1-second intervals, effective per-measurement overhead reduces from 657\,ms to 65.7\,ms (90.0\% latency reduction) with 10-second aggregation latency. This strategy suits applications tolerating batched delivery (environmental monitoring, usage metering) but remains inappropriate for real-time event reporting requiring immediate transmission.

\textbf{Hybrid authentication}: Selective ML-DSA deployment for security-critical messages (firmware updates, configuration changes, alerts) combined with MAC-based authentication for routine telemetry reduces average authentication overhead while maintaining non-repudiation for critical operations. For deployment patterns comprising 90\% routine telemetry (MAC authentication: 0.5\,ms overhead) and 10\% critical messages (ML-DSA-44: 657\,ms overhead), weighted average overhead totals 66.2\,ms compared to 657\,ms for pure ML-DSA deployment (89.9\% reduction). This approach requires security analysis of message classification policies and MAC key management infrastructure.

\textbf{Hardware acceleration}: Future ARM Cortex-M processors incorporating cryptographic acceleration extensions for NTT operations, modular arithmetic, or Keccak hashing could provide performance improvements. While current-generation IoT microcontrollers lack post-quantum cryptographic acceleration, industry roadmaps suggest specialized instruction set extensions may appear in 2027--2029 timeframes, potentially achieving 5--10$\times$ performance improvements through dedicated NTT hardware and reducing ML-DSA signing latency to sub-100-millisecond ranges. Until hardware acceleration availability, software optimization techniques establish performance upper bounds for ARM Cortex-M4 platforms.


This analysis provides guidance for IoT system designers evaluating post-quantum migration strategies through quantification of ML-DSA deployment costs and constraints.

\section{Conclusion}\label{sec:conclusion}

This work presents comprehensive performance characterization of ML-DSA integration within MQTT-based IoT systems on ARM Cortex-M4 microcontrollers and proposes an adaptive security level selection protocol optimizing resource utilization in heterogeneous IoT deployments. Experimental evaluation across all three standardized parameter sets quantifies the computational, memory, and protocol-level costs of post-quantum signature-based authentication in resource-constrained environments.

Performance measurements reveal substantial overhead relative to classical ECDSA signatures. Signature generation latencies of 657--1,150\,ms across ML-DSA parameter sets represent 70--122$\times$ overhead compared to ECDSA P-256, establishing signature generation as the primary computational bottleneck limiting sustainable message throughput to 0.87--1.52 messages per second. Verification operations exhibit 26--44$\times$ overhead with latencies of 416--717\,ms. Memory requirements of 22.7--43.1\,KB SRAM and 37.2--73.9\,KB Flash constrain deployment to mid-range microcontrollers with adequate memory resources. Message size overhead of 2,420--4,627 bytes per signature dominates payload composition for typical IoT sensor data, impacting bandwidth consumption in constrained networks.

The proposed adaptive security level selection protocol addresses the inefficiency of fixed highest-security configurations by dynamically selecting ML-DSA parameter sets based on message criticality, device resource state, and operational context. Evaluation across representative IoT workloads demonstrates 15.8--41.2\% signing latency reduction compared to fixed ML-DSA-87 deployment, with environmental monitoring workloads achieving maximum benefit due to predominant low-criticality message composition. For battery-powered deployments, adaptive selection extends operational lifetime by 18.8--55.2\% through energy-aware parameter selection, while maintaining minimum security guarantees per message criticality class. Protocol overhead of 23--38 $\mu$s per message represents less than 0.006\% of signing latency, rendering adaptive selection computationally negligible.

These findings establish deployment feasibility boundaries for post-quantum authenticated IoT messaging. ML-DSA remains viable for applications tolerating multi-second latency and sub-hertz publication frequencies, including environmental monitoring, asset tracking, and periodic telemetry reporting. Real-time control systems requiring sub-second response necessitate architectural accommodations or hybrid authentication approaches. The adaptive protocol provides a practical mechanism for optimizing post-quantum authentication overhead without compromising security guarantees for critical operations.

Future research directions include hardware acceleration evaluation on emerging ARM Cortex-M processors with cryptographic extensions, batch signature verification schemes for gateway devices processing multiple authenticated streams, and formal security analysis of adaptive parameter selection under adversarial resource manipulation. As post-quantum cryptographic standards mature and hardware support expands, the adaptive protocol and performance characterization presented in this work will inform practical migration strategies for resource-constrained IoT systems transitioning to quantum-resistant authentication.

\bibliographystyle{IEEEtran_doi}
\bibliography{ biblio.bib }

%\vspace{-1.2cm}
\begin{IEEEbiographynophoto}{Jiahao Xiang}
	is pursuing a Master's degree in Electronic Information at Hengyang Normal University, China. His research focuses on cryptographic engineering and efficient implementations of block ciphers on resource-constrained devices. Publications include works on lightweight cryptography optimization and contributions to open-source cryptographic projects.
\end{IEEEbiographynophoto}

\vskip -2\baselineskip plus -1fil

\begin{IEEEbiographynophoto}{Lang Li}
	received his Ph.D. and Master's degrees in computer science from Hunan University, Changsha, China, in 2010 and 2006, respectively, and earned his B.S. degree in circuits and systems from Hunan Normal University in 1996. Since 2011, he has been working as a professor in the College of Computer Science and Technology at the Hengyang Normal University, Hengyang, China. He has research interests in embedded system and information security.
\end{IEEEbiographynophoto}

\vskip -2\baselineskip plus -1fil

\begin{IEEEbiographynophoto} {Jingya Feng}
	received the M.S. degree from Hunan Normal University, Changsha, China, in 2021, and the Ph.D. degree from Guilin University of Electronic Science and Technology, Guilin, China, in 2025. She Joined the School of Computer Science and Technology, Hengyang Normal University in July 2025. Her main research interests include cryptology, with particular focus on the design and optimized implementation of symmetric encryption schemes.
\end{IEEEbiographynophoto}

\end{document}
